<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Practice | Bowen's Blog]]></title>
  <link href="http://iambowen.github.com/blog/categories/practice/atom.xml" rel="self"/>
  <link href="http://iambowen.github.com/"/>
  <updated>2016-11-19T22:34:38+11:00</updated>
  <id>http://iambowen.github.com/</id>
  <author>
    <name><![CDATA[Bowen Ma]]></name>
    <email><![CDATA[iambowen.m@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Stop Wrapping AWS SDK to Create Tools]]></title>
    <link href="http://iambowen.github.com/aws/practice/2015/12/29/stopping-creating-new-wheels"/>
    <updated>2015-12-29T01:24:42+11:00</updated>
    <id>http://iambowen.github.com/aws/practice/2015/12/29/stopping-creating-new-wheels</id>
    <content type="html"><![CDATA[<p>大概4-5年前，客户开始使用AWS作为他们的开发和测试环境，因为澳洲当时没有亚马逊的数据中心，所以只好
使用us-east, us-west这些region。后来澳洲有了AWS的数据中心，应用的产品就都迁移到新的region
和新的AWS账户下。由于这个历史原因，一部分bake AMI的任务以及部署的任务，都是跨账户以及region
的。</p>

<p>这些任务的工具，都是用ruby的<code>aws-sdk</code>包装的，从表面上看，这么做有如下的好处:</p>

<ol>
<li>更细粒度去控制这些任务以及过程</li>
<li>代码可测试</li>
<li>打包/发布/共享会更加容易些</li>
<li>只要SDK支持，你都可以用自己熟悉的语言去实现这些工具</li>
<li>写代码实现感觉很牛逼</li>
</ol>


<p>对于程序员来说，这么做感觉棒棒哒，写完很有满足感。但是实际中会带来很大的问题，具体表现在维护方面。
我举两个例子：</p>

<ol>
<li>不是所有人都喜欢这个工具，有些人会提交patch，改进这个工具，有些人会重新实现一个类似功能的工
具，比如我喜欢用Java，但是现有的工具是用Ruby实现，我表示不服，重头写一个。维护的难度在这种分散
的项目和语言中增大了。</li>
<li>实现者没有在对工具进行维护，其中依赖的sdk已经过期，而作为工具的使用者，并没有察觉到这件事情，
在实际的使用中会遇到问题，面对非常深的stacktrace，debug的难度较高。</li>
</ol>


<p>最近，我和同事就碰到了这样的问题。我们AMI构建和部署的工具是用Ruby的<code>aws-sdk</code>实现，我们要做的工
作是把构建AMI和部署的任务从一个AWS Account移到另外一个Account，原本的验证方式是通过Hard
Code的Credentials如<code>AWS_SECRET_ACCESS_KEY/AWS_ACCESS_KEY_ID</code>。更好的实践是通过STS服务
，用AssumeRole的方式去获得临时的Credential。听上去并没有什么太大的难度，但是当我们去迁移的时
候，发现始终提示权限不足，而仔细检查role的权限后发现没有任何不妥，于是百思不得其解，尝试追踪
stacktrace也没什么结果。</p>

<p>无意中看了眼<code>Gemfile</code>，感觉<code>aws-sdk</code>的版本有点低，随手升了个级，然后试了下，竟然可以通过验证
了……。</p>

<p>多花了两个小时，就是因为没有再去维护这个工具。而这个工具实际实现的功能，用<code>aws-cli</code>也可
以很容易实现，而且依赖更少：</p>

<ol>
<li>本地使用，只需要有<code>aws-cli</code>(可能还有python，除了windows，一般的系统默认都会有)和bash就可
以了</li>
<li>CI的slave上使用，可以让<code>aws-cli</code>在镜像启动时自动更新，这样就完全不需要维护</li>
<li>如果cli参数有变动，提示会更加直接些，也容易追踪</li>
</ol>


<p>所以，如果大家要针对AWS做一些开发，比如镜像构建，清理或者自动化部署，推荐使用CLI的方式，而不是
SDK去实现，从使用的角度，依赖更少，从维护的角度，成本更低。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Don't Copy/paste Keys From Chatting Tools]]></title>
    <link href="http://iambowen.github.com/ssh/practice/2015/12/17/dont-copy-slash-paste-keys-from-chatting-tools"/>
    <updated>2015-12-17T19:58:30+11:00</updated>
    <id>http://iambowen.github.com/ssh/practice/2015/12/17/dont-copy-slash-paste-keys-from-chatting-tools</id>
    <content type="html"><![CDATA[<p>今天，别的组的同事过来问我一个关于SSH的问题，问题是这样的:</p>

<ol>
<li>客户把AWS的ssh instance的private key通过slack拷给了同事；</li>
<li>同事发现用部署工具<a href="http://www.fabfile.org/">fabric</a>可以使用该key，ssh到EC2的instance上进行部署；</li>
<li>但是如果使用key去ssh(如<code>ssh -i key user@instance</code>)到EC2的instance，就会提示输入<code>passphrase</code></li>
<li>客户的Ops很肯定说这个private key没有加<code>passphrase</code></li>
</ol>


<p>这个问题很有趣，我先查看了下key，在我的印象里，如果在<code>ssh-keygen</code>的时候加入密码保护了，private
key 中会有如下的额外信息:</p>

<pre><code>-----BEGIN RSA PRIVATE KEY-----
Proc-Type: 4,ENCRYPTED
DEK-Info: AES-128-CBC,B88893260B6CCFDC6304101075B74A9F
.....
</code></pre>

<p>但是同事给我的private key中没有.</p>

<p>在不同的系统下尝试用该key去ssh到EC2 instance得到的结果都是需要输入passpharse,通过输入冗余
ssh信息<code>ssh -vvvv</code>也没有看到什么有用信息(其实是我忽略了)。</p>

<p>google搜索，猜测会不会是key generate时候的格式不同导致的，但是觉得这种可能性不高。</p>

<p>在客户的ops channel询问了下，有人给出了这个建议，用
<code>
openssl rsa -text -noout -in KEYFILE
</code>
去检查key的完整性,返回结果如下:</p>

<pre><code>[vagrant@localhost ~]$ openssl rsa -text -noout -in id_rsa
unable to load Private Key
140516793460640:error:0906D066:PEM routines:PEM_read_bio:bad end line:pem_lib.c:802:
</code></pre>

<p>实际上这个信息已经比较明显了，另外有人也从ssh debug的信息中指出:</p>

<pre><code>debug1: key_parse_private2: missing begin marker
debug1: key_parse_private_pem: PEM_read_PrivateKey failed
</code></pre>

<p>private key的开始或者结束的marker出问题了，于是客户询问这个key是不是从slack拷贝过去的，因为
聊天工具有时候会自动纠错，把结束的marker <code>----</code>自动改成<code>——</code>，他曾经就遇到过这种情况。
再看一遍private key，果然是这样……好羞愧。修改后，果然可以顺利ssh 到instance上了。
(更正下，虽然他指出了问题的来源，但是这段debug信息，在private key是完整的情况下仍然存在，所以这不是key出错的绝对证据。)</p>

<p>从这个事情中，我们可以得到一些教训</p>

<ol>
<li>不要用聊天工具copy/paste private key或者代码之类的东西，很容易引起错误。</li>
<li>同时，这种方式也很不安全，尽量不要这么做，要么在传递完后迅速删除聊天记录</li>
<li>或者使用一个公共的key管理的服务，如<a href="http://rattic.org/">rattic</a>，或者使用临时生成的credential来ssh，如这个<a href="https://github.com/realestate-com-au/sshephalopod">项目</a>进一步提高安全性。</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Make Everything Production Like - (2/2)]]></title>
    <link href="http://iambowen.github.com/practice/aws/2015/12/06/make-everything-production-like-2-slash-2"/>
    <updated>2015-12-06T20:12:21+11:00</updated>
    <id>http://iambowen.github.com/practice/aws/2015/12/06/make-everything-production-like-2-slash-2</id>
    <content type="html"><![CDATA[<p><a href="http://iambowen.github.io/2015/07/05/make-everything-production-like/">开发环境出问题的时候，影响到只是自己</a>，如果持续集成环境或者其相关的基础设施出了问题，那影响到的就
是所有人以及整个开发的进展，我们曾经遇到一次这样的事故，整个 <a href="https://www.atlassian.com/software/bamboo">Bamboo</a>(CI)环境的Master和Database都被干掉了，出乎意料的是AWS RDS的自动镜像同时也被删除,于是所有的人花了一个礼拜才重新建好了全部的流水线。</p>

<p>除此之外，一些基础设施，比如企业私有的Repository(如Nexus, Koji, rubygems服务器等)出现问题，也会影响到整个开发和持续交付的时间。</p>

<p>如何解决这个问题？很简单，提高这些环境的可用性，把他们当做产品环境一样看待，提高出错的响应速度，
减少平均恢复时间等。</p>

<p>先举一个CI环境当做产品环境来对待的例子。
一些简单的背景:</p>

<ol>
<li>客户使用的持续集成工具是<a href="https://www.atlassian.com/software/bamboo">Bamboo</a></li>
<li>CI Master，Agent以及数据库服务都采用了AWS的服务，如EC2、RDS、R53等</li>
<li>用CloudFormation去管理整个CI服务的基础设施，同时用Rake task去简化管理的难度。</li>
</ol>


<p>其具体的结构图如下:
<img src="http://7xp2qy.com1.z0.glb.clouddn.com/bamboo_arch.png" alt="arch" /></p>

<p>该结构详细解释如下:</p>

<ol>
<li>Bamboo Agent和 Bamboo Master的依赖及其配置打包成RPM，部署的EC2 instance基于Centos定制过的AMI</li>
<li>Bamboo Master/Agent/DB 都用CloudFormation管理</li>
<li>在Bamboo Agent Stack的LaunchConfiguration中的Metadata中，安装在Agent中运行各种build的依赖，
比如不同的Ruby版本等，同时定义<code>cfn-hup</code>服务，监听Agent的Stack变化，如果有Metadata的变化，
比如，更新了Agent上支持的Java版本，则在Agent上更新该配置</li>
<li>Bamboo Agent由一个AutoScalingGroup管理，除了自动Scale，还可以每天定时启动或者停止Agent
Instance，节省成本</li>
<li>Bamboo Master的Stack中做的事情类似</li>
<li>Bamboo Master的SecurityGroup只接受来自Bamboo Agent的SecurityGroup的访问，Bamboo
Master DB的SecurityGroup只接受来自Bamboo Master SecurityGroup的请求</li>
<li>Bamboo Master DB使用RDS服务</li>
<li>Bamboo Master服务器上运行的Cron Job每天会定时备份文件系统的Snapshot</li>
<li>Bamboo 服务器上的一个Plan每天会运行定时的任务，创建Master DB的Snapshot,RDS可以设置自动
生成snapshot，不过一旦Master DB被干掉，snapshot也会被一起干掉。所以，安全期间，还是manual
snapshot比较好。</li>
</ol>


<p>回顾这套结构，如果某个Agent挂掉，AutoScalingGroup会重新spin up一个新的Agent Instance。
如果Bamboo Master或者Master DB挂掉，也可以通过CloudFormation Stack以及备份的Snapshot
在1-2个小时以内恢复，时间的开销相对较少。</p>

<p>仔细的同学可能会注意到，为了满足运行build的各种条件，需要安装各种依赖，比如不同的Ruby版本，
不同的Java版本等，重新创建一个Agent Instance到配置完成注册成为Bamboo服务，时间会比较长。而且
如果Metadata的更新导致环境失败，会迅速影响到所有的Agent。</p>

<p>相信很多人会想到更好的解决方案，比如将每个build任务都在Docker容器中运行，如此作为整个CI环境
的维护者，只需要保证每个Agent上面有docker deamon运行，整个Agent挂掉的几率大大降低，同时维护
的责任分散到每个团队内，减轻了维护的压力。</p>

<p>下面介绍如何提高企业内部的私有Repository，如Nexus的可用性和稳定性以及快速恢复能力。
我们的Nexus服务器的结构图，如下:
<img src="http://7xp2qy.com1.z0.glb.clouddn.com/nexus_arch.png" alt="nexus arch" /></p>

<p>详细解释如下:</p>

<ol>
<li>Nexus服务运行在ELB后的一个EC2 Instance上</li>
<li>其部署基于安装有Nexus服务的Base AMI以及CloudFormation stack</li>
<li>Nexus的artifact目录挂载在一个EBS volume下，Instance在初始化时配置了InstanceProfile，
在crontab添加脚本，可以用InstanceProfile中的role去创建EBS volume的daily snapshot，以防止artifact数据丢失</li>
<li>监控方面，如果ELB下面的健康的Instance数量少于1或者Instance上的EBS Volume没有正确的挂载，都会触发Cloudwatch Alarm，并通过SNS通知Pagerduty，然后Pagerduty再将警报发给维护Nexus的Ops</li>
</ol>


<p>对于上面的Nexus结构，由于有足够的备份，不论是Volume挂载失败需要恢复或者是Instance当机，处理的
时间成本都会比较低，在半个小时以内。</p>

<p>开发/测试依赖的环境可能还有很多，更多的把它们当做产品环境对待，会大大增加持续交付的流畅度，减轻环境维护方面的痛楚。</p>
]]></content>
  </entry>
  
</feed>
