<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Aws | Bowen's Blog]]></title>
  <link href="http://iambowen.github.com/blog/categories/aws/atom.xml" rel="self"/>
  <link href="http://iambowen.github.com/"/>
  <updated>2016-07-03T14:37:09+08:00</updated>
  <id>http://iambowen.github.com/</id>
  <author>
    <name><![CDATA[Bowen Ma]]></name>
    <email><![CDATA[iambowen.m@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[AWS KMS and Its Usage]]></title>
    <link href="http://iambowen.github.com/aws/kms/2016/01/15/aws-kms-and-its-usage"/>
    <updated>2016-01-15T09:33:30+08:00</updated>
    <id>http://iambowen.github.com/aws/kms/2016/01/15/aws-kms-and-its-usage</id>
    <content type="html"><![CDATA[<h2>什么是KMS</h2>

<hr />

<p><a href="https://aws.amazon.com/kms/">KMS</a>是AWS提供的中心化的key托管服务，它使用硬件安全模块 (HSM)保护密钥安全。它可以被集成到其它的AWS服务中，如S3, EBS, RDS等，同时所有关于key的使用都会在CloudTrail中记录，以方便审计。</p>

<h2>KMS的优点</h2>

<hr />

<p>基本上来自于<a href="https://aws.amazon.com/kms/">文档</a>，其好处有如下几点：</p>

<ol>
<li>中心化的key托管服务。举个例子，对于不同的环境(staging/production)，我们需要维护不同private key 去做部署，调试等等，还得考虑定期rotate。出于安全考虑，这些private key不推荐和部署的repo放在一起。一般情况下你得把它们放在一个统一的地方去保存，如<a href="http://rattic.org/">Rattic</a>或者<a href="https://www.vaultproject.io/">Vault</a>去管理。这样的话，你的承担这些工具的维护任务。KMS可以让你免除维护的压力。</li>
<li>和 AWS 服务的集成。S3，EBS，RDS的数据加密，都可以使用KMS。同时，它也支持命令行或者API去管理key，进行key的rotate，加密解密等。</li>
<li>可伸缩性、耐用性和高可用性。KMS会自动帮你保存key多份拷贝，耐用性99.999999999%，同时KMS会在多个AZ部署，保证高可用性。</li>
<li>安全。KMS在服务端通过硬件加密，保证了你在上面存储的key的安全性。其实现的细节在<a href="https://d0.awsstatic.com/whitepapers/KMS-Cryptographic-Details.pdf">这里</a></li>
<li>审计。对于key的请求，都会被记录在CloudTrail中，方便审计。</li>
</ol>


<p>可以看到的好处有很多，比如直接把加密过后的private key或者密码扔到repo中，再也不用担心被别人拿去干坏事。</p>

<h2>使用 KMS 服务</h2>

<hr />

<p>要使用KMS服务，首先得创建一个新的master key。key是按照region划分， 自己创建key的价格是1刀一个月，每个月的前20000次请求是免费的。</p>

<h3>创建新key</h3>

<hr />

<p>在AWS Console -> IAM界面的<code>Encryption Keys</code>中找到创建Key和Key管理的选项，如key的<code>Enable</code>、<code>Disable</code>或者删除等。当然，我们可以通过AWS CLI来创建key，这样可以将整个过程用代码管理起来:</p>

<ol>
<li>假设AWS account为<code>123456789</code>,指定key policy并保存到文件(e.g <code>policy.json</code>)中</li>
</ol>


<pre><code class="json">{
  "Id": "KeyPolicy-1",
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "Allow access for Admin",
      "Effect": "Allow",
      "Principal": {
        "AWS": "arn:aws:iam::123456789:root"
      },
      "Action": [
        "kms:Create*",
        "kms:Describe*",
        "kms:Enable*",
        "kms:List*",
        "kms:Put*",
        "kms:Update*",
        "kms:Revoke*",
        "kms:Disable*",
        "kms:Get*",
        "kms:Delete*",
        "kms:ScheduleKeyDeletion",
        "kms:CancelKeyDeletion"
      ],
      "Resource": "*"
    }
  ]
}
</code></pre>

<ol>
<li>创建key，并绑定对应的policy</li>
</ol>


<pre><code class="bash"> ~&gt; aws kms create-key --key-usage "encryption key" --description "master key" --policy "$(cat policy.json)"
</code></pre>

<p>返回的内容可能如下
<code>json
{
  "KeyMetadata": {
    "KeyId": "aabbccdd-4444-5555-6666-778899001122",
      "Description": "master key",
      "Enabled": true,
      "KeyUsage": "encryption key",
      "CreationDate": 2433401783.841,
      "Arn": "arn:aws:kms:ap-southeast-2:123456789:key/aabbccdd-4444-5555-6666-778899001122",
      "AWSAccountId": "123456789"
  }
}
</code>
3. 授权IAM user/role去使用或者管理key,这是除了policy之外的另一种访问管理控制的机制。</p>

<pre><code class="bash">{
  "Sid": "Allow use of the key",
  "Effect": "Allow",
  "Principal": {"AWS": [
    "arn:aws:iam::111122223333:user/KMSUser",
    "arn:aws:iam::111122223333:role/KMSRole",
  ]},
  "Action": [
    "kms:Encrypt",
    "kms:Decrypt",
    "kms:ReEncrypt*",
    "kms:GenerateDataKey*",
    "kms:DescribeKey"
  ],
  "Resource": "*"
}
</code></pre>

<ol>
<li>创建alias,可以作为keyid的替身使用</li>
</ol>


<pre><code class="bash">aws kms create-alias --alias-name "alias/test-encryption-key" --target-key-id aabbccdd-4444-5555-6666-778899001122
</code></pre>

<ol>
<li>使用key去加密文件。加密后的输出为base64编码后的密文，可以进一步解码为二进制文件。</li>
</ol>


<pre><code class="bash">aws kms encrypt --key-id 1234abcd-12ab-34cd-56ef-1234567890ab --plaintext fileb://ExamplePlaintextFile --output text --query CiphertextBlob | base64 --decode &gt; ExampleEncryptedFile
</code></pre>

<ol>
<li>解密文件，原理如加密的过程。</li>
</ol>


<pre><code class="bash">aws kms decrypt --ciphertext-blob fileb://ExampleEncryptedFile --output text --query Plaintext | base64 --decode &gt; ExamplePlaintextFile
</code></pre>

<h3>局限性</h3>

<p>这种使用KMS的方式只能加密最多4KB的数据。想要加密更大的数据可以使用KMS去生成一个<a href="http://docs.aws.amazon.com/kms/latest/developerguide/workflow.html">Data Key</a>，然后利用Data Key去加密数据。</p>

<h3>使用场景举例</h3>

<p>在REA项目中，在AWS上部署的大多数APP都是（尽量）遵循12factors原则的。应用运行时依赖的配置是通过<code>user-data</code>传入环境变量设置。在一个instance上启动服务的过程大致如下：
1. 在<code>launchConfiguration</code>中为instance添加<code>instanceProfile</code>，对应的role有使用KMS的权限；
2. 在<code>user-data</code>中设置cypher text并且解密到环境变量中:</p>

<pre><code class="bash">cipher="CiBwo3lXT5T+pTZu7P9Cqkh0Iolpaz9FMzha5jJb6kTdiBKNAQEBAgB4cKN5V0+U/qU2buz/QqpIdCKJaWs/RTM4WuYyW+pE3YgAAABkMGIGCSqGSIb3DQEHBqBVMFMCAQAwTgYJKoZIhvcNAQcBMB4GCWCGSAFlAwQBLjARBAwIxkIN0TeX1HiWyj0CARCAIVaSfD/spTBFAfBVIp/Wy6TadlwUKKz/oTMWUUob9fcxdg=="
cipher_blob=$(mktemp /tmp/blob.123)
echo -n "${cipher}" | base64 -D &gt; cipher_blob
PASSWORD=$(aws kms decrypt --ciphertext-blob fileb://$cipher_blob \
             --query "Plaintext"                         \
             --output text                               \
             --region ap-southeast-2  | \
             base64 -D
)

docker run -d -e PASSWORD=$PASSWORD .......
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ci Solution With Mesos]]></title>
    <link href="http://iambowen.github.com/ci/mesos/aws/2016/01/10/ci-solution-with-mesos"/>
    <updated>2016-01-10T14:33:29+08:00</updated>
    <id>http://iambowen.github.com/ci/mesos/aws/2016/01/10/ci-solution-with-mesos</id>
    <content type="html"><![CDATA[<p>上次在<a href="http://www.meetup.com/Infrastructure-Coders/">Melbourne Infrastructure-Coders</a>上介绍过一次，比较惨，改进了一遍后，这次重新在<a href="http://gdgxian.org/">GDG Xi'an</a>讲了下，还是中文讲起来比较6。</p>

<p>屁屁踢如下:</p>

<script async class="speakerdeck-embed" data-id="f32cb7fad8ec4785b1b48c91eaccd8db" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js"></script>


<p>Demo的环境是在本地实现的，repo在这里:<a href="https://github.com/iambowen/ansible-mesos">https://github.com/iambowen/ansible-mesos</a></p>

<p>看不到屁屁踢的，请设置DNS为8.8.8.8或者翻墙……</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Stop Wrapping AWS SDK to Create Tools]]></title>
    <link href="http://iambowen.github.com/aws/practice/2015/12/28/stopping-creating-new-wheels"/>
    <updated>2015-12-28T22:24:42+08:00</updated>
    <id>http://iambowen.github.com/aws/practice/2015/12/28/stopping-creating-new-wheels</id>
    <content type="html"><![CDATA[<p>大概4-5年前，客户开始使用AWS作为他们的开发和测试环境，因为澳洲当时没有亚马逊的数据中心，所以只好
使用us-east, us-west这些region。后来澳洲有了AWS的数据中心，应用的产品就都迁移到新的region
和新的AWS账户下。由于这个历史原因，一部分bake AMI的任务以及部署的任务，都是跨账户以及region
的。</p>

<p>这些任务的工具，都是用ruby的<code>aws-sdk</code>包装的，从表面上看，这么做有如下的好处:</p>

<ol>
<li>更细粒度去控制这些任务以及过程</li>
<li>代码可测试</li>
<li>打包/发布/共享会更加容易些</li>
<li>只要SDK支持，你都可以用自己熟悉的语言去实现这些工具</li>
<li>写代码实现感觉很牛逼</li>
</ol>


<p>对于程序员来说，这么做感觉棒棒哒，写完很有满足感。但是实际中会带来很大的问题，具体表现在维护方面。
我举两个例子：</p>

<ol>
<li>不是所有人都喜欢这个工具，有些人会提交patch，改进这个工具，有些人会重新实现一个类似功能的工
具，比如我喜欢用Java，但是现有的工具是用Ruby实现，我表示不服，重头写一个。维护的难度在这种分散
的项目和语言中增大了。</li>
<li>实现者没有在对工具进行维护，其中依赖的sdk已经过期，而作为工具的使用者，并没有察觉到这件事情，
在实际的使用中会遇到问题，面对非常深的stacktrace，debug的难度较高。</li>
</ol>


<p>最近，我和同事就碰到了这样的问题。我们AMI构建和部署的工具是用Ruby的<code>aws-sdk</code>实现，我们要做的工
作是把构建AMI和部署的任务从一个AWS Account移到另外一个Account，原本的验证方式是通过Hard
Code的Credentials如<code>AWS_SECRET_ACCESS_KEY/AWS_ACCESS_KEY_ID</code>。更好的实践是通过STS服务
，用AssumeRole的方式去获得临时的Credential。听上去并没有什么太大的难度，但是当我们去迁移的时
候，发现始终提示权限不足，而仔细检查role的权限后发现没有任何不妥，于是百思不得其解，尝试追踪
stacktrace也没什么结果。</p>

<p>无意中看了眼<code>Gemfile</code>，感觉<code>aws-sdk</code>的版本有点低，随手升了个级，然后试了下，竟然可以通过验证
了……。</p>

<p>多花了两个小时，就是因为没有再去维护这个工具。而这个工具实际实现的功能，用<code>aws-cli</code>也可
以很容易实现，而且依赖更少：</p>

<ol>
<li>本地使用，只需要有<code>aws-cli</code>(可能还有python，除了windows，一般的系统默认都会有)和bash就可
以了</li>
<li>CI的slave上使用，可以让<code>aws-cli</code>在镜像启动时自动更新，这样就完全不需要维护</li>
<li>如果cli参数有变动，提示会更加直接些，也容易追踪</li>
</ol>


<p>所以，如果大家要针对AWS做一些开发，比如镜像构建，清理或者自动化部署，推荐使用CLI的方式，而不是
SDK去实现，从使用的角度，依赖更少，从维护的角度，成本更低。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Make Everything Production Like - (2/2)]]></title>
    <link href="http://iambowen.github.com/practice/aws/2015/12/06/make-everything-production-like-2-slash-2"/>
    <updated>2015-12-06T17:12:21+08:00</updated>
    <id>http://iambowen.github.com/practice/aws/2015/12/06/make-everything-production-like-2-slash-2</id>
    <content type="html"><![CDATA[<p><a href="http://iambowen.github.io/2015/07/05/make-everything-production-like/">开发环境出问题的时候，影响到只是自己</a>，如果持续集成环境或者其相关的基础设施出了问题，那影响到的就
是所有人以及整个开发的进展，我们曾经遇到一次这样的事故，整个 <a href="https://www.atlassian.com/software/bamboo">Bamboo</a>(CI)环境的Master和Database都被干掉了，出乎意料的是AWS RDS的自动镜像同时也被删除,于是所有的人花了一个礼拜才重新建好了全部的流水线。</p>

<p>除此之外，一些基础设施，比如企业私有的Repository(如Nexus, Koji, rubygems服务器等)出现问题，也会影响到整个开发和持续交付的时间。</p>

<p>如何解决这个问题？很简单，提高这些环境的可用性，把他们当做产品环境一样看待，提高出错的响应速度，
减少平均恢复时间等。</p>

<p>先举一个CI环境当做产品环境来对待的例子。
一些简单的背景:</p>

<ol>
<li>客户使用的持续集成工具是<a href="https://www.atlassian.com/software/bamboo">Bamboo</a></li>
<li>CI Master，Agent以及数据库服务都采用了AWS的服务，如EC2、RDS、R53等</li>
<li>用CloudFormation去管理整个CI服务的基础设施，同时用Rake task去简化管理的难度。</li>
</ol>


<p>其具体的结构图如下:
<img src="http://7xp2qy.com1.z0.glb.clouddn.com/bamboo_arch.png" alt="arch" /></p>

<p>该结构详细解释如下:</p>

<ol>
<li>Bamboo Agent和 Bamboo Master的依赖及其配置打包成RPM，部署的EC2 instance基于Centos定制过的AMI</li>
<li>Bamboo Master/Agent/DB 都用CloudFormation管理</li>
<li>在Bamboo Agent Stack的LaunchConfiguration中的Metadata中，安装在Agent中运行各种build的依赖，
比如不同的Ruby版本等，同时定义<code>cfn-hup</code>服务，监听Agent的Stack变化，如果有Metadata的变化，
比如，更新了Agent上支持的Java版本，则在Agent上更新该配置</li>
<li>Bamboo Agent由一个AutoScalingGroup管理，除了自动Scale，还可以每天定时启动或者停止Agent
Instance，节省成本</li>
<li>Bamboo Master的Stack中做的事情类似</li>
<li>Bamboo Master的SecurityGroup只接受来自Bamboo Agent的SecurityGroup的访问，Bamboo
Master DB的SecurityGroup只接受来自Bamboo Master SecurityGroup的请求</li>
<li>Bamboo Master DB使用RDS服务</li>
<li>Bamboo Master服务器上运行的Cron Job每天会定时备份文件系统的Snapshot</li>
<li>Bamboo 服务器上的一个Plan每天会运行定时的任务，创建Master DB的Snapshot,RDS可以设置自动
生成snapshot，不过一旦Master DB被干掉，snapshot也会被一起干掉。所以，安全期间，还是manual
snapshot比较好。</li>
</ol>


<p>回顾这套结构，如果某个Agent挂掉，AutoScalingGroup会重新spin up一个新的Agent Instance。
如果Bamboo Master或者Master DB挂掉，也可以通过CloudFormation Stack以及备份的Snapshot
在1-2个小时以内恢复，时间的开销相对较少。</p>

<p>仔细的同学可能会注意到，为了满足运行build的各种条件，需要安装各种依赖，比如不同的Ruby版本，
不同的Java版本等，重新创建一个Agent Instance到配置完成注册成为Bamboo服务，时间会比较长。而且
如果Metadata的更新导致环境失败，会迅速影响到所有的Agent。</p>

<p>相信很多人会想到更好的解决方案，比如将每个build任务都在Docker容器中运行，如此作为整个CI环境
的维护者，只需要保证每个Agent上面有docker deamon运行，整个Agent挂掉的几率大大降低，同时维护
的责任分散到每个团队内，减轻了维护的压力。</p>

<p>下面介绍如何提高企业内部的私有Repository，如Nexus的可用性和稳定性以及快速恢复能力。
我们的Nexus服务器的结构图，如下:
<img src="http://7xp2qy.com1.z0.glb.clouddn.com/nexus_arch.png" alt="nexus arch" /></p>

<p>详细解释如下:</p>

<ol>
<li>Nexus服务运行在ELB后的一个EC2 Instance上</li>
<li>其部署基于安装有Nexus服务的Base AMI以及CloudFormation stack</li>
<li>Nexus的artifact目录挂载在一个EBS volume下，Instance在初始化时配置了InstanceProfile，
在crontab添加脚本，可以用InstanceProfile中的role去创建EBS volume的daily snapshot，以防止artifact数据丢失</li>
<li>监控方面，如果ELB下面的健康的Instance数量少于1或者Instance上的EBS Volume没有正确的挂载，都会触发Cloudwatch Alarm，并通过SNS通知Pagerduty，然后Pagerduty再将警报发给维护Nexus的Ops</li>
</ol>


<p>对于上面的Nexus结构，由于有足够的备份，不论是Volume挂载失败需要恢复或者是Instance当机，处理的
时间成本都会比较低，在半个小时以内。</p>

<p>开发/测试依赖的环境可能还有很多，更多的把它们当做产品环境对待，会大大增加持续交付的流畅度，减轻环境维护方面的痛楚。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Specifying Amazon Credentials in Packer]]></title>
    <link href="http://iambowen.github.com/packer/aws/2015/12/02/specifying-amazon-credentials-in-packer"/>
    <updated>2015-12-02T20:50:33+08:00</updated>
    <id>http://iambowen.github.com/packer/aws/2015/12/02/specifying-amazon-credentials-in-packer</id>
    <content type="html"><![CDATA[<p><a href="https://packer.io/">Packer</a>是一个用一份配置构建跨平台镜像的工具，它支持EC2 AMI，Vmware，
QEMU，Virtualbox，docker等多个平台。</p>

<p>我们使用AWS作为基础设施平台，通过EC2 AMI作为镜像部署，构建AMI工具基于Packer，加上了一些定制
的东西以减少配置，简化使用的方式。</p>

<p>Packer在构建AMI时，需要创建临时的key pair,security group以及EC2实例，因为需要对应的API
credentials,像这样:</p>

<pre><code class="bash">access key id:     AKIAIOSFODNN7EXAMPLE
secret access key: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
</code></pre>

<p>所以Packer需要在配置文件中hard code credentials或者通过环境变量传入，如果这些都没有找到，
Packer会通过如下的步骤去自动查找credential:</p>

<p>1.查找AWS相关环境变量，如:</p>

<pre><code class="bash">AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE
AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
</code></pre>

<p>2.寻找AWS配置文件<code>~/.aws/credentials</code>或者<code>AWS_PROFILE</code>环境变量</p>

<p>3.查找运行Packer的EC2实例中<a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2_instance-profiles.html">instance profile</a>中的role，然后用AWS STS(Security Token Service)来获取临时的credential.该role的policy至少要允许如下的Actions:</p>

<pre><code class="json">{
  "Statement": [{
      "Effect": "Allow",
      "Action" : [
        "ec2:AttachVolume",
        "ec2:CreateVolume",
        "ec2:DeleteVolume",
        "ec2:CreateKeypair",
        "ec2:DeleteKeypair",
        "ec2:CreateSecurityGroup",
        "ec2:DeleteSecurityGroup",
        "ec2:AuthorizeSecurityGroupIngress",
        "ec2:CreateImage",
        "ec2:RunInstances",
        "ec2:TerminateInstances",
        "ec2:StopInstances",
        "ec2:DescribeVolumes",
        "ec2:DetachVolume",
        "ec2:DescribeInstances",
        "ec2:CreateSnapshot",
        "ec2:DeleteSnapshot",
        "ec2:DescribeSnapshots",
        "ec2:DescribeImages",
        "ec2:RegisterImage",
        "ec2:CreateTags",
        "ec2:ModifyImageAttribute"
      ],
      "Resource" : "*"
  }]
}
</code></pre>

<p>这几种方式中，使用instance profile的的方式是最好的，原因大致如下:</p>

<ol>
<li>固定credential的方式会带来安全隐患，一旦泄露，会导致巨大的损失。</li>
<li>从安全的角度考虑，API credential需要rotate，这样会带来维护成本。读取配置文件也有同样的
问题。</li>
<li>在持续集成流水线AMI构建任务中，credential必须通过环境变量的方式传入，任务本身增加了额外的
依赖，维护成本提高。</li>
</ol>


<p>之所以总结Packer在构建AMI时指定credential的方式，是因为最近在把一个用packer构建AMI的流水线
从一个Region移到另一个Region时遇到了原有的credential不工作的情况，后来发现，其实运行这个任务
的Agent(EC2实例)初始化时就绑定了instance profile，不用设置任何额外的credential，packer可以
自动去读取，于是在移除了原有的各种credential之后，顺利的构建出了镜像。</p>
]]></content>
  </entry>
  
</feed>
